{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4c7d65-b6b3-48bf-b059-2448507f24ec",
   "metadata": {},
   "source": [
    "# **SWA, Apex AMP & Interpreting Transformers in Torch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4575545-3686-4172-9c7b-14371bba1e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import multiprocessing\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn import model_selection\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "import torch.optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import (\n",
    "    Dataset, DataLoader,\n",
    "    SequentialSampler, RandomSampler\n",
    ")\n",
    "\n",
    "import transformers\n",
    "from madgrad import MADGRAD\n",
    "\n",
    "from transformers import (\n",
    "    WEIGHTS_NAME,\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModel,\n",
    "    RobertaTokenizer,\n",
    "    RobertaModel,\n",
    "    AutoTokenizer,\n",
    "    get_cosine_schedule_with_warmup,\n",
    "    logging,\n",
    "    MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING,\n",
    "    get_cosine_schedule_with_warmup, \n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    RobertaConfig,\n",
    ")\n",
    "\n",
    "import re\n",
    "from lit_nlp.api import dataset as lit_dataset\n",
    "from lit_nlp.api import types as lit_types\n",
    "from lit_nlp.api import model as lit_model\n",
    "from lit_nlp.lib import utils\n",
    "\n",
    "logging.set_verbosity_warning()\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f3b7c4e-5d6d-4275-8193-6d9cf15e9663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apex AMP Installed :: True\n",
      "SWA Available :: True\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from apex import amp\n",
    "    APEX_INSTALLED = True\n",
    "except ImportError:\n",
    "    APEX_INSTALLED = False\n",
    "\n",
    "from madgrad import MADGRAD\n",
    "\n",
    "try:\n",
    "    from torch.optim.swa_utils import (\n",
    "        AveragedModel, update_bn, SWALR\n",
    "    )\n",
    "    SWA_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SWA_AVAILABLE = False\n",
    "\n",
    "\n",
    "def fix_all_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def optimal_num_of_loader_workers():\n",
    "    num_cpus = multiprocessing.cpu_count()\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    optimal_value = min(num_cpus, num_gpus*4) if num_gpus else num_cpus - 1\n",
    "    return optimal_value\n",
    "\n",
    "\n",
    "print(f\"Apex AMP Installed :: {APEX_INSTALLED}\")\n",
    "print(f\"SWA Available :: {SWA_AVAILABLE}\")\n",
    "MODEL_CONFIG_CLASSES = list(MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING.keys())\n",
    "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d10d1e1-c54c-4698-ac52-acaea98a751d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(MODEL_CONFIG_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60583e58-de28-43c4-9a6c-8a95979511a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  standard_error  \n",
       "0  When the young people returned to the ballroom... -0.340259        0.464009  \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372        0.480805  \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118        0.476676  \n",
       "3  And outside before the palace a great garden w... -1.054013        0.450007  \n",
       "4  Once upon a time there were Three Bears who li...  0.247197        0.510845  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./train.csv', low_memory=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "502e5d99-132c-4db0-8fb4-0ee335b7f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folds(data, num_splits):\n",
    "    data[\"kfold\"] = -1\n",
    "    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state=2023)\n",
    "    for f, (t_, v_) in enumerate(kf.split(X=data)):\n",
    "        data.loc[v_, 'kfold'] = f\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dbb7551-2120-4d90-8d30-ac2752b019c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_folds(train, num_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0521262-cd79-4ba5-871f-0411ba1f1845",
   "metadata": {},
   "source": [
    "## **Train Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cf9defc-115b-4b64-a4da-6f8f951ded61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # model\n",
    "    num_labels = 1\n",
    "    model_type = 'roberta'\n",
    "    model_name_or_path = 'roberta-base'\n",
    "    config_name = 'roberta-base'\n",
    "    fp16 = True if APEX_INSTALLED else False\n",
    "    fp16_opt_level = \"O1\"\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer_name = 'roberta-base'\n",
    "    max_seq_length = 250\n",
    "\n",
    "    # train\n",
    "    epochs = 10\n",
    "    train_batch_size = 24\n",
    "    eval_batch_size = 16\n",
    "\n",
    "    # optimizer\n",
    "    optimizer_type = 'MADGRAD'\n",
    "    learning_rate = 2e-5\n",
    "    weight_decay = 1e-5\n",
    "    epsilon = 1e-6\n",
    "    max_grad_norm = 1.0\n",
    "\n",
    "    # stochastic weight averaging\n",
    "    swa = True\n",
    "    swa_start = 7\n",
    "    swa_learning_rate = 1e-4\n",
    "    anneal_epochs=3 \n",
    "    anneal_strategy='cos'\n",
    "\n",
    "    # scheduler\n",
    "    decay_name = 'cosine-warmup'\n",
    "    warmup_ratio = 0.03\n",
    "\n",
    "    # logging\n",
    "    logging_steps = 10\n",
    "\n",
    "    # evaluate\n",
    "    output_dir = 'output'\n",
    "    seed = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6ef22-19cb-44e6-99e2-44be54e9d174",
   "metadata": {},
   "source": [
    "## **Average Meter (Will help us in logging metrics)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "207f6801-4ba9-4b23-a7a3-b79fdae6d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "        self.max = 0\n",
    "        self.min = 1e5\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        if val > self.max:\n",
    "            self.max = val\n",
    "        if val < self.min:\n",
    "            self.min = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "674baba2-b056-4e46-8039-a3ab5493785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        super(DatasetRetriever, self).__init__()\n",
    "        self.data = data\n",
    "        self.is_test = is_test\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        if not self.is_test:\n",
    "            self.targets = self.data.target.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        excerpt = self.excerpts[item]\n",
    "        features = self.convert_examples_to_features(\n",
    "            excerpt, self.tokenizer, \n",
    "            self.max_len\n",
    "        )\n",
    "        features = {key : torch.tensor(value, dtype=torch.long) for key, value in features.items()}\n",
    "        if not self.is_test:\n",
    "            label = self.targets[item]\n",
    "            features['labels'] = torch.tensor(label, dtype=torch.double)\n",
    "        return features\n",
    "    \n",
    "    def convert_examples_to_features(self, example, tokenizer, max_len):\n",
    "        features = tokenizer.encode_plus(\n",
    "            example.replace('\\n', ''), \n",
    "            max_length=max_len, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "        )\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf952b6-6821-4d54-81ca-74ca2e1dcd17",
   "metadata": {},
   "source": [
    "## **Define Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b3e991-8720-475b-a3b5-6e8cfffb454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, model_name, config):\n",
    "        \n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.roberta = AutoModel.from_pretrained(\n",
    "            model_name, \n",
    "            config=config\n",
    "        )\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.high_dropout = nn.Dropout(p=0.5)\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size, eps=1e-5)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self.regressor = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self._init_weights(self.regressor)\n",
    "        \n",
    "        weights_init = torch.zeros(config.num_hidden_layers + 1).float()\n",
    "        weights_init.data[:-1] = -3\n",
    "        self.layer_weights = torch.nn.Parameter(weights_init)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        all_hidden_states = outputs[2]\n",
    "        \n",
    "        # weighted layer pooling\n",
    "        cls_embeddings = torch.stack(\n",
    "            [self.dropout(layer[:, 0]) for layer in all_hidden_states], \n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        cls_output = (\n",
    "            torch.softmax(self.layer_weights, dim=0) * cls_embeddings\n",
    "        ).sum(-1)\n",
    "        \n",
    "        cls_output = self.layer_norm(cls_output)\n",
    "        \n",
    "        # multi-sample dropout\n",
    "        logits = torch.mean(\n",
    "            torch.stack(\n",
    "                [self.regressor(self.high_dropout(cls_output)) for _ in range(5)],\n",
    "                dim=0,\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # regression task\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        output = (logits,) + outputs[2:]\n",
    "        \n",
    "        del all_hidden_states, cls_embeddings\n",
    "        del cls_output, logits\n",
    "        gc.collect();\n",
    "        \n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d3b230-8900-45ac-9459-61b74f3e83fe",
   "metadata": {},
   "source": [
    "## **Grouped Optimizer Parameters & LLRD**\n",
    "We will be using Grouped-LLRD (Layer Wise Learning Rate Decay) since from my experiments this shows better peformance and generalization than simple LLRD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be2556e5-41cc-4944-b231-fe28bea0c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer_grouped_parameters(args, model):\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n",
    "    group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n",
    "    group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n",
    "    group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': args.weight_decay},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': args.weight_decay, 'lr': args.learning_rate/2.6},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': args.weight_decay, 'lr': args.learning_rate},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': args.weight_decay, 'lr': args.learning_rate*2.6},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': args.learning_rate/2.6},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': args.learning_rate},\n",
    "        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': args.learning_rate*2.6},\n",
    "        {'params': [p for n, p in model.named_parameters() if args.model_type not in n], 'lr':args.learning_rate*20, \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    return optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc2660d-24e7-40ca-ad4e-f3d360e25085",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(args, output_attentions=False):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.tokenizer_name)\n",
    "    config = AutoConfig.from_pretrained(args.config_name)\n",
    "    config.update({'num_labels':args.num_labels})\n",
    "    config.update({\"output_hidden_states\":True})\n",
    "    if output_attentions:\n",
    "        config.update({\"output_attentions\":True})\n",
    "    model = Model(args.model_name_or_path, config=config)\n",
    "    return model, config, tokenizer\n",
    "\n",
    "\n",
    "\n",
    "def make_optimizer(args, model):\n",
    "    optimizer_grouped_parameters = get_optimizer_grouped_parameters(args, model)\n",
    "    if args.optimizer_type == \"AdamW\":\n",
    "        optimizer = AdamW(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=args.learning_rate,\n",
    "            eps=args.epsilon,\n",
    "            correct_bias=not args.use_bertadam\n",
    "        )\n",
    "    else:\n",
    "        optimizer = MADGRAD(\n",
    "            optimizer_grouped_parameters,\n",
    "            lr=args.learning_rate,\n",
    "            eps=args.epsilon,\n",
    "            weight_decay=args.weight_decay\n",
    "        )\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "\n",
    "def make_scheduler(args, optimizer, num_warmup_steps, num_training_steps):\n",
    "    if args.decay_name == \"cosine-warmup\":\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "    else:\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "    return scheduler\n",
    "\n",
    "\n",
    "def make_loader(args, data, tokenizer, fold):\n",
    "    \n",
    "    train_set, valid_set = data[data['kfold']!=fold], data[data['kfold']==fold]\n",
    "\n",
    "    train_dataset = DatasetRetriever(train_set, tokenizer, args.max_seq_length)\n",
    "    valid_dataset = DatasetRetriever(valid_set, tokenizer, args.max_seq_length)\n",
    "    print(f\"Num examples Train= {len(train_dataset)}, Num examples Valid={len(valid_dataset)}\")\n",
    "    \n",
    "    train_sampler = RandomSampler(train_dataset)\n",
    "    valid_sampler = SequentialSampler(valid_dataset)\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.train_batch_size,\n",
    "        sampler=train_sampler,\n",
    "        shuffle=True,\n",
    "        num_workers=optimal_num_of_loader_workers(),\n",
    "        pin_memory=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=args.eval_batch_size, \n",
    "        sampler=valid_sampler,\n",
    "        shuffle=False,\n",
    "        num_workers=optimal_num_of_loader_workers(),\n",
    "        pin_memory=True, \n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8ca12-00cb-4197-9e99-03504f4c6033",
   "metadata": {},
   "source": [
    "## **Define Trainer Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a5fa45a-b429-4d41-8298-83dd70f41bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, model, tokenizer, optimizer, scheduler, swa_model=None, swa_scheduler=None):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.swa_model = swa_model\n",
    "        self.swa_scheduler = swa_scheduler\n",
    "\n",
    "    def train(self, args, train_dataloader, epoch, result_dict):\n",
    "        count = 0\n",
    "        losses = AverageMeter()\n",
    "        \n",
    "        self.model.zero_grad()\n",
    "        self.model.train()\n",
    "        \n",
    "        fix_all_seeds(args.seed)\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(train_dataloader):\n",
    "            input_ids, attention_mask, labels = batch_data['input_ids'], batch_data['attention_mask'], batch_data['labels']\n",
    "            input_ids, attention_mask, labels = input_ids.cuda(), attention_mask.cuda(), labels.cuda()\n",
    "\n",
    "            outputs = self.model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "\n",
    "            loss, logits = outputs[:2]\n",
    "            \n",
    "            if args.fp16:\n",
    "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            count += labels.size(0)\n",
    "            losses.update(loss.item(), input_ids.size(0))\n",
    "\n",
    "            if args.fp16:\n",
    "                torch.nn.utils.clip_grad_norm_(amp.master_params(self.optimizer), args.max_grad_norm)\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), args.max_grad_norm)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            if not args.swa:\n",
    "                self.scheduler.step()\n",
    "            else:\n",
    "                if (epoch+1) < args.swa_start:\n",
    "                    self.scheduler.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            if (batch_idx % args.logging_steps == 0) or (batch_idx+1)==len(train_dataloader):\n",
    "                _s = str(len(str(len(train_dataloader.sampler))))\n",
    "                ret = [\n",
    "                    ('Epoch: {:0>1} [{: >' + _s + '}/{} ({: >3.0f}%)]').format(epoch, count, len(train_dataloader.sampler), 100 * count / len(train_dataloader.sampler)),\n",
    "                    'Train Loss: {: >4.5f}'.format(losses.avg),\n",
    "                ]\n",
    "                print(', '.join(ret))\n",
    "                \n",
    "        if args.swa and (epoch+1) >= args.swa_start:\n",
    "            self.swa_model.update_parameters(self.model)\n",
    "            self.swa_scheduler.step()\n",
    "\n",
    "        result_dict['train_loss'].append(losses.avg)\n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af61051-7a83-4a56-af6a-f30236c142cf",
   "metadata": {},
   "source": [
    "## **Define Evaluator Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f921f10a-8003-4c79-b16a-3f43b7d46350",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, swa_model):\n",
    "        self.model = model\n",
    "        self.swa_model = swa_model\n",
    "    \n",
    "    def save(self, result, output_dir):\n",
    "        with open(f'{output_dir}/result_dict.json', 'w') as f:\n",
    "            f.write(json.dumps(result, sort_keys=True, indent=4, ensure_ascii=False))\n",
    "\n",
    "    def evaluate(self, valid_dataloader, epoch, result_dict):\n",
    "        losses = AverageMeter()\n",
    "        for batch_idx, batch_data in enumerate(valid_dataloader):\n",
    "            self.model = self.model.eval()\n",
    "            input_ids, attention_mask, labels = \\\n",
    "                batch_data['input_ids'], batch_data['attention_mask'], batch_data['labels']\n",
    "            input_ids, attention_mask, labels = \\\n",
    "                input_ids.cuda(), attention_mask.cuda(), labels.cuda()\n",
    "            with torch.no_grad():            \n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss, logits = outputs[:2]\n",
    "                losses.update(loss.item(), input_ids.size(0))\n",
    "        print('----Validation Results Summary----')\n",
    "        print('Epoch: [{}] Valid Loss: {: >4.5f}'.format(epoch, losses.avg))\n",
    "        result_dict['val_loss'].append(losses.avg)        \n",
    "        return result_dict\n",
    "    \n",
    "    def swa_evaluate(self, valid_dataloader, epoch, result_dict):\n",
    "        losses = AverageMeter()\n",
    "        for batch_idx, batch_data in enumerate(valid_dataloader):\n",
    "            self.swa_model = self.swa_model.eval()\n",
    "            input_ids, attention_mask, labels = \\\n",
    "                batch_data['input_ids'], batch_data['attention_mask'], batch_data['labels']\n",
    "            input_ids, attention_mask, labels = \\\n",
    "                input_ids.cuda(), attention_mask.cuda(), labels.cuda()\n",
    "            with torch.no_grad():            \n",
    "                outputs = self.swa_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                loss, logits = outputs[:2]\n",
    "                losses.update(loss.item(), input_ids.size(0))\n",
    "        print('----SWA Validation Results Summary----')\n",
    "        print('Epoch: [{}] Valid Loss: {: >4.5f}'.format(epoch, losses.avg))\n",
    "        result_dict['swa_loss'].append(losses.avg)        \n",
    "        return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dc43f26-c199-463d-be6d-80e04a3fadc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_training(args, data, fold):\n",
    "    fix_all_seeds(args.seed)\n",
    "    \n",
    "    if not os.path.exists(args.output_dir):\n",
    "        os.makedirs(args.output_dir)\n",
    "    \n",
    "    # model\n",
    "    model, model_config, tokenizer = make_model(args)\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "    \n",
    "    # data loaders for training and evaluation\n",
    "    train_dataloader, valid_dataloader = make_loader(args, data, tokenizer, fold)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = make_optimizer(args, model)\n",
    "\n",
    "    # scheduler\n",
    "    num_training_steps = len(train_dataloader) * args.epochs\n",
    "    if args.warmup_ratio > 0:\n",
    "        num_warmup_steps = int(args.warmup_ratio * num_training_steps)\n",
    "    else:\n",
    "        num_warmup_steps = 0\n",
    "    print(f\"Total Training Steps: {num_training_steps}, Total Warmup Steps: {num_warmup_steps}\")\n",
    "    scheduler = make_scheduler(args, optimizer, num_warmup_steps, num_training_steps)\n",
    "\n",
    "    # stochastic weight averaging\n",
    "    swa_model = AveragedModel(model)\n",
    "    swa_scheduler = SWALR(\n",
    "        optimizer, swa_lr=args.swa_learning_rate, \n",
    "        anneal_epochs=args.anneal_epochs, \n",
    "        anneal_strategy=args.anneal_strategy\n",
    "    )\n",
    "\n",
    "    print(f\"Total Training Steps: {num_training_steps}, Total Warmup Steps: {num_warmup_steps}, SWA Start Step: {args.swa_start}\")\n",
    "\n",
    "    # mixed precision training with NVIDIA Apex\n",
    "    if args.fp16:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=args.fp16_opt_level)\n",
    "    \n",
    "    result_dict = {\n",
    "        'epoch':[], \n",
    "        'train_loss': [], \n",
    "        'val_loss' : [], \n",
    "        'swa_loss': [],\n",
    "        'best_val_loss': np.inf\n",
    "    }\n",
    "\n",
    "    return (\n",
    "        model, model_config, tokenizer, optimizer, scheduler, \n",
    "        train_dataloader, valid_dataloader, result_dict,\n",
    "        swa_model, swa_scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f2def0e-9096-40d3-83c7-6603b0c80392",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data, fold):\n",
    "    \n",
    "    args = Config()\n",
    "    \n",
    "    model, model_config, tokenizer, optimizer, scheduler, train_dataloader, \\\n",
    "        valid_dataloader, result_dict, swa_model, swa_scheduler = init_training(args, data, fold)\n",
    "    \n",
    "    trainer = Trainer(model, tokenizer, optimizer, scheduler, swa_model, swa_scheduler)\n",
    "    evaluator = Evaluator(model, swa_model)\n",
    "\n",
    "    train_time_list = []\n",
    "    valid_time_list = []\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        result_dict['epoch'].append(epoch)\n",
    "\n",
    "        # Train\n",
    "        torch.cuda.synchronize()\n",
    "        tic1 = time.time()\n",
    "        result_dict = trainer.train(\n",
    "            args, train_dataloader, \n",
    "            epoch, result_dict\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        tic2 = time.time() \n",
    "        train_time_list.append(tic2 - tic1)\n",
    "        \n",
    "        # Evaluate\n",
    "        torch.cuda.synchronize()\n",
    "        tic3 = time.time()\n",
    "        result_dict = evaluator.evaluate(\n",
    "            valid_dataloader, epoch, result_dict\n",
    "        )\n",
    "        torch.cuda.synchronize()\n",
    "        tic4 = time.time() \n",
    "        valid_time_list.append(tic4 - tic3)\n",
    "            \n",
    "        output_dir = os.path.join(args.output_dir, f\"checkpoint-fold-{fold}\")\n",
    "        if result_dict['val_loss'][-1] < result_dict['best_val_loss']:\n",
    "            print(\"{} Epoch, Best epoch was updated! Valid Loss: {: >4.5f}\".format(epoch, result_dict['val_loss'][-1]))\n",
    "            result_dict[\"best_val_loss\"] = result_dict['val_loss'][-1]        \n",
    "            \n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), f\"{output_dir}/pytorch_model.bin\")\n",
    "            model_config.save_pretrained(output_dir)\n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "            print(f\"Saving model checkpoint to {output_dir}.\")\n",
    "    \n",
    "            #torch.save(optimizer.state_dict(), os.path.join(output_dir, \"optimizer.pt\"))\n",
    "            #torch.save(scheduler.state_dict(), os.path.join(output_dir, \"scheduler.pt\"))\n",
    "            #print(f\"Saving optimizer and scheduler states to {output_dir}.\")\n",
    "        print()\n",
    "        \n",
    "    if args.swa:\n",
    "        update_bn(train_dataloader, swa_model, device=torch.device('cuda'))\n",
    "    result_dict = evaluator.swa_evaluate(valid_dataloader, epoch, result_dict)\n",
    "    \n",
    "    evaluator.save(result_dict, output_dir)\n",
    "    torch.save(swa_model.state_dict(), f\"{output_dir}/swa_pytorch_model.bin\")\n",
    "    \n",
    "    print()\n",
    "    print(f\"Total Training Time: {np.sum(train_time_list)}secs, Average Training Time per Epoch: {np.mean(train_time_list)}secs.\")\n",
    "    print(f\"Total Validation Time: {np.sum(valid_time_list)}secs, Average Validation Time per Epoch: {np.mean(valid_time_list)}secs.\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    del trainer, evaluator\n",
    "    del model, model_config, tokenizer\n",
    "    del optimizer, scheduler\n",
    "    del train_dataloader, valid_dataloader, result_dict\n",
    "    del swa_model, swa_scheduler\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4390b5-9475-4af6-b911-6c2cc909c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold in range(5):\n",
    "    print();print()\n",
    "    print('-'*50)\n",
    "    print(f'FOLD: {fold}')\n",
    "    print('-'*50)\n",
    "    run(train, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2930a8-e4d0-4a63-ba2a-9b20020089e3",
   "metadata": {},
   "source": [
    "## **Implement Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c58bb80b-0ea2-46e9-9977-fa2b63bc035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonLitData(lit_dataset.Dataset):\n",
    "    def __init__(self, df, fold, split='val'):\n",
    "        self._examples = self.load_datapoints(df, fold, split)\n",
    "    \n",
    "    def load_datapoints(self, df, fold, split):\n",
    "        if split == 'val':\n",
    "            df = df[df['kfold']==fold].reset_index()\n",
    "        else:\n",
    "            df = df[df['kfold']!=fold].reset_index()\n",
    "        return [{\n",
    "            \"excerpt\": row[\"excerpt\"],\n",
    "            \"label\": row[\"target\"],\n",
    "        } for _, row in df.iterrows()]\n",
    "\n",
    "    def spec(self):\n",
    "        return {\n",
    "            'excerpt': lit_types.TextSegment(),\n",
    "            'label': lit_types.RegressionScore(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a867109-38c9-464c-b68c-4cf78cacdbfd",
   "metadata": {},
   "source": [
    "## **Implement Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65cdf457-ce2f-4e5b-9094-b3f941d15316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonLitModel(lit_model.Model):\n",
    "    compute_grads = False\n",
    "    def __init__(self, args):\n",
    "        self.model, self.config, self.tokenizer = make_model(args, output_attentions=True)\n",
    "        self.model.eval()\n",
    "\n",
    "    def max_minibatch_size(self):\n",
    "        return 8\n",
    "\n",
    "    def predict_minibatch(self, inputs):\n",
    "        encoded_input = self.tokenizer.batch_encode_plus(\n",
    "            [ex[\"excerpt\"].replace(\"\\n\", \"\") for ex in inputs],\n",
    "            add_special_tokens=True,\n",
    "            max_length=256,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        encoded_input = {\n",
    "            key : torch.tensor(value, dtype=torch.long) for key, value in encoded_input.items()\n",
    "        }\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.model.cuda()\n",
    "            for tensor in encoded_input:\n",
    "                encoded_input[tensor] = encoded_input[tensor].cuda()\n",
    "    \n",
    "        with torch.set_grad_enabled(self.compute_grads):\n",
    "            outputs = self.model(encoded_input['input_ids'], encoded_input['attention_mask'])\n",
    "            if self.model.config.output_attentions:\n",
    "                logits, hidden_states, output_attentions = outputs[0], outputs[1], outputs[2]\n",
    "            else:\n",
    "                logits, hidden_states = outputs[0], outputs[1]\n",
    "\n",
    "        batched_outputs = {\n",
    "            \"input_ids\": encoded_input[\"input_ids\"],\n",
    "            \"ntok\": torch.sum(encoded_input[\"attention_mask\"], dim=1),\n",
    "            \"cls_emb\": hidden_states[-1][:, 0],\n",
    "            \"score\": torch.squeeze(logits, dim=-1)\n",
    "        }\n",
    "        \n",
    "        if self.model.config.output_attentions:\n",
    "            assert len(output_attentions) == self.model.config.num_hidden_layers\n",
    "            for i, layer_attention in enumerate(output_attentions[-2:]):\n",
    "                batched_outputs[f\"layer_{i}/attention\"] = layer_attention\n",
    "\n",
    "        if self.compute_grads:\n",
    "            scalar_pred_for_gradients = batched_outputs[\"score\"]\n",
    "            batched_outputs[\"input_emb_grad\"] = torch.autograd.grad(\n",
    "                scalar_pred_for_gradients,\n",
    "                hidden_states[0],\n",
    "                grad_outputs=torch.ones_like(scalar_pred_for_gradients)\n",
    "            )[0]\n",
    "\n",
    "        detached_outputs = {k: v.cpu().numpy() for k, v in batched_outputs.items()}\n",
    "        for output in utils.unbatch_preds(detached_outputs):\n",
    "            ntok = output.pop(\"ntok\")\n",
    "            output[\"tokens\"] = self.tokenizer.convert_ids_to_tokens(\n",
    "                output.pop(\"input_ids\")[1:ntok - 1]\n",
    "            )\n",
    "            if self.compute_grads:\n",
    "                output[\"token_grad_sentence\"] = output[\"input_emb_grad\"][:ntok]\n",
    "            if self.model.config.output_attentions:\n",
    "                for key in output:\n",
    "                    if not re.match(r\"layer_(\\d+)/attention\", key):\n",
    "                        continue\n",
    "                    output[key] = output[key][:, :ntok, :ntok].transpose((0, 2, 1))\n",
    "                    output[key] = output[key].copy()\n",
    "            yield output\n",
    "\n",
    "    def input_spec(self) -> lit_types.Spec:\n",
    "        return {\n",
    "            \"excerpt\": lit_types.TextSegment(),\n",
    "            \"label\": lit_types.RegressionScore()\n",
    "        }\n",
    "\n",
    "    def output_spec(self) -> lit_types.Spec:\n",
    "        ret = {\n",
    "            \"tokens\": lit_types.Tokens(),\n",
    "            \"score\": lit_types.RegressionScore(parent=\"label\"),\n",
    "            \"cls_emb\": lit_types.Embeddings()\n",
    "        }\n",
    "        if self.compute_grads:\n",
    "            ret[\"token_grad_sentence\"] = lit_types.TokenGradients(\n",
    "                align=\"tokens\"\n",
    "            )\n",
    "        if self.model.config.output_attentions:\n",
    "            for i in range(2): # self.model.config.num_hidden_layers\n",
    "                ret[f\"layer_{i}/attention\"] = lit_types.AttentionHeads(\n",
    "                    align_in=\"tokens\", align_out=\"tokens\")\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f936f334-0465-40ca-a6ed-88b8eb2aeb0a",
   "metadata": {},
   "source": [
    "## **Run**\n",
    "\n",
    "Now we load our 5-Fold Validation Data and Models, pass that to notebook.LitWidget and call widget.render().\r\n",
    "\r\n",
    "This in return will open an interface like below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682d191-6d16-415e-8b6a-eb71115a2087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(path):\n",
    "    args = Config()\n",
    "    args.config_name = path\n",
    "    args.model_name_or_path = path\n",
    "    args.tokenizer_name = path\n",
    "    return CommonLitModel(args)\n",
    "\n",
    "datasets = {\n",
    "    'validation_0':CommonLitData(train, fold=0, split='val'),\n",
    "    'validation_1':CommonLitData(train, fold=1, split='val'),\n",
    "    'validation_2':CommonLitData(train, fold=2, split='val'),\n",
    "    'validation_3':CommonLitData(train, fold=3, split='val'),\n",
    "    'validation_4':CommonLitData(train, fold=4, split='val'),\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'model_0':create_model('output/checkpoint-fold-0/'),\n",
    "    'model_1':create_model('output/checkpoint-fold-1/'),\n",
    "    'model_2':create_model('output/checkpoint-fold-2/'),\n",
    "    'model_3':create_model('output/checkpoint-fold-3/'),\n",
    "    'model_4':create_model('output/checkpoint-fold-4/'),\n",
    "}\n",
    "\n",
    "\n",
    "from lit_nlp import notebook\n",
    "widget = notebook.LitWidget(models, datasets, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8098eef-3741-45dc-a671-6af7c4e766f5",
   "metadata": {},
   "source": [
    "## **Infer & Estimate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3e15d39-22f7-49c7-a60e-37b095a64d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n",
    "    data = data.replace('\\n', '')\n",
    "    tok = tokenizer.encode_plus(\n",
    "        data, \n",
    "        max_length=max_len, \n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_token_type_ids=True\n",
    "    )\n",
    "    curr_sent = {}\n",
    "    padding_length = max_len - len(tok['input_ids'])\n",
    "    curr_sent['input_ids'] = tok['input_ids'] + ([0] * padding_length)\n",
    "    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n",
    "        ([0] * padding_length)\n",
    "    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n",
    "        ([0] * padding_length)\n",
    "    return curr_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f426b9-bcce-493b-9f7b-55e3fa3f6ea7",
   "metadata": {},
   "source": [
    "### **Dataset Retriever**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1052ce8c-3014-4f62-bb63-86c4f60c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, is_test=False):\n",
    "        self.data = data\n",
    "        self.excerpts = self.data.excerpt.values.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.is_test = is_test\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not self.is_test:\n",
    "            excerpt, label = self.excerpts[item], self.targets[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "                'label':torch.tensor(label, dtype=torch.double),\n",
    "            }\n",
    "        else:\n",
    "            excerpt = self.excerpts[item]\n",
    "            features = convert_examples_to_features(\n",
    "                excerpt, self.tokenizer, \n",
    "                self.max_len, self.is_test\n",
    "            )\n",
    "            return {\n",
    "                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n",
    "                'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n",
    "                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53df747b-2de8-4be0-afce-e0ab74ec1345",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonLitModel(nn.Module):\n",
    "    def __init__(self, model_name, config, multisample_dropout=False, output_hidden_states=False):\n",
    "        super(CommonLitModel, self).__init__()\n",
    "        self.config = config\n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            model_name, \n",
    "            output_hidden_states=output_hidden_states\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(config.hidden_size)\n",
    "        if multisample_dropout:\n",
    "            self.dropouts = nn.ModuleList([\n",
    "                nn.Dropout(0.5) for _ in range(5)\n",
    "            ])\n",
    "        else:\n",
    "            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n",
    "        self.regressor = nn.Linear(config.hidden_size, 1)\n",
    "        self._init_weights(self.layer_norm)\n",
    "        self._init_weights(self.regressor)\n",
    " \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    " \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "        )\n",
    "        sequence_output = outputs[1]\n",
    "        sequence_output = self.layer_norm(sequence_output)\n",
    " \n",
    "        # multi-sample dropout\n",
    "        for i, dropout in enumerate(self.dropouts):\n",
    "            if i == 0:\n",
    "                logits = self.regressor(dropout(sequence_output))\n",
    "            else:\n",
    "                logits += self.regressor(dropout(sequence_output))\n",
    "        \n",
    "        logits /= len(self.dropouts)\n",
    " \n",
    "        # calculate loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = torch.nn.MSELoss()\n",
    "            logits = logits.view(-1).to(labels.dtype)\n",
    "            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n",
    "        \n",
    "        output = (logits,) + outputs[1:]\n",
    "        return ((loss,) + output) if loss is not None else output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d22a4684-0b92-4736-9b23-d39edd36b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(model_name, num_labels=1):\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    config = RobertaConfig.from_pretrained(model_name)\n",
    "    config.update({'num_labels':num_labels})\n",
    "    model = CommonLitModel(model_name, config=config)\n",
    "    return model, tokenizer\n",
    "\n",
    "def make_loader(data, tokenizer, max_len, batch_size):\n",
    "    \n",
    "    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size // 2, \n",
    "        sampler=test_sampler, \n",
    "        pin_memory=False, \n",
    "        drop_last=False, \n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5147c620-dda2-4db7-9d8b-d80a248f5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    def __init__(self, model, scalar=None):\n",
    "        self.model = model\n",
    "        self.scalar = scalar\n",
    "\n",
    "    def evaluate(self, data_loader, tokenizer):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_data in enumerate(data_loader):\n",
    "                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n",
    "                    batch_data['attention_mask'], batch_data['token_type_ids']\n",
    "                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n",
    "                    attention_mask.cuda(), token_type_ids.cuda()\n",
    "                \n",
    "                if self.scalar is not None:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids\n",
    "                        )\n",
    "                else:\n",
    "                    outputs = self.model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=token_type_ids\n",
    "                    )\n",
    "                \n",
    "                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n",
    "                preds += logits\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c20aff8e-fb41-4390-98c8-7869fe68bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    " def EstimatorConfig(fold, model_name, load_model_path):\n",
    "    torch.manual_seed(2023)\n",
    "    torch.cuda.manual_seed(2023)\n",
    "    torch.cuda.manual_seed_all(2023)\n",
    "    \n",
    "    max_len = 250\n",
    "    batch_size = 8\n",
    "\n",
    "    model, tokenizer = make_model(\n",
    "        model_name=model_name, \n",
    "        num_labels=1\n",
    "    )\n",
    "    model.load_state_dict(\n",
    "        torch.load(f'{load_model_path}/model{fold}.bin')\n",
    "    )\n",
    "    test_loader = make_loader(\n",
    "        test, tokenizer, max_len=max_len,\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    if torch.cuda.device_count() >= 1:\n",
    "        print('Model pushed to {} GPU(s), type {}.'.format(\n",
    "            torch.cuda.device_count(), \n",
    "            torch.cuda.get_device_name(0))\n",
    "        )\n",
    "        model = model.cuda() \n",
    "    else:\n",
    "        raise ValueError('CPU training is not supported')\n",
    "\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    return (\n",
    "        model, tokenizer, \n",
    "        test_loader, scaler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "911f97bb-cfd4-420d-89a4-4357305a496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold=0, model_name=None, load_model_path=None):\n",
    "    model, tokenizer, \\\n",
    "        test_loader, scaler = EstimatorConfig(fold, model_name, load_model_path)\n",
    "    \n",
    "    import time\n",
    "\n",
    "    evaluator = Estimator(model, scaler)\n",
    "\n",
    "    test_time_list = []\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic1 = time.time()\n",
    "\n",
    "    preds = evaluator.evaluate(test_loader, tokenizer)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    tic2 = time.time() \n",
    "    test_time_list.append(tic2 - tic1)\n",
    "    \n",
    "    del model, tokenizer, test_loader, scaler\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c99e34-703a-440d-9f76-2639cfabf266",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df1 = pd.DataFrame()\n",
    "pred_df2 = pd.DataFrame()\n",
    "pred_df3 = pd.DataFrame()\n",
    "for fold in tqdm(range(5)):\n",
    "    pred_df1[f'fold{fold}'] = run(fold, '../input/roberta-base/', '../input/commonlit-roberta-base-i/')\n",
    "    pred_df2[f'fold{fold+5}'] = run(fold, '../input/robertalarge/', '../input/roberta-large-itptfit/')\n",
    "    pred_df3[f'fold{fold+10}'] = run(fold, '../input/robertalarge/', '../input/commonlit-roberta-large-ii/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0750560-d7ff-4046-b2da-321455a722cf",
   "metadata": {},
   "source": [
    "## **Make Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7e09c4-efb7-498b-895e-554b19ce6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n",
    "# sub['target'] = ((pred_df1.mean(axis=1) + pred_df2.mean(axis=1) + pred_df3.mean(axis=1))/3).values.tolist()\n",
    "sub['target'] = (pred_df2.mean(axis=1)*0.5) + (pred_df1.mean(axis=1)*0.3) + (pred_df3.mean(axis=1) * 0.2).values.tolist()\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
